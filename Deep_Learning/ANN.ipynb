{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ANN.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1nakXcBk0DNGbAaMnpPR96HylY4R4X-Xz","authorship_tag":"ABX9TyP/yFc5nKPgsBoMUbwzSUjt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Data Preprocessing**"],"metadata":{"id":"4n526auOqvFX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7FWc_HoCm6g-"},"outputs":[],"source":["#Importing libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf"]},{"cell_type":"code","source":["tf.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"FzP0juF_r5rN","executionInfo":{"status":"ok","timestamp":1650741943204,"user_tz":-330,"elapsed":16,"user":{"displayName":"Kunal Kashyap","userId":"03732283627136928542"}},"outputId":"44cdc2a3-0763-4b0b-c874-980ca8f1cd99"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.8.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["#Importing datasets\n","df = pd.read_csv('/content/drive/MyDrive/Machine Learning A-Z (Codes and Datasets)/Part 8 - Deep Learning/Section 39 - Artificial Neural Networks (ANN)/Python/Churn_Modelling.csv')\n","x = df.iloc[:,3:-1].values\n","y = df.iloc[:,-1].values"],"metadata":{"id":"AMg2HDl9o5rg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(x)\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UuAklyxLtQ28","executionInfo":{"status":"ok","timestamp":1650741943206,"user_tz":-330,"elapsed":16,"user":{"displayName":"Kunal Kashyap","userId":"03732283627136928542"}},"outputId":"118593d6-53e7-4f9d-bca8-9154eeb5808f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[619 'France' 'Female' ... 1 1 101348.88]\n"," [608 'Spain' 'Female' ... 0 1 112542.58]\n"," [502 'France' 'Female' ... 1 0 113931.57]\n"," ...\n"," [709 'France' 'Female' ... 0 1 42085.58]\n"," [772 'Germany' 'Male' ... 1 0 92888.52]\n"," [792 'France' 'Female' ... 1 0 38190.78]]\n","[1 0 1 ... 1 1 0]\n"]}]},{"cell_type":"code","source":["#Missing Values\n","#Categorical Encoding(Label Encoding on Gender Column)\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","x[:,2] = le.fit_transform(x[:,2])\n","print(x)\n","print('\\n\\n')\n","#One hot Encoder on Geography column\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1])],remainder=\"passthrough\")\n","# all remaining colunms that were not specified in tarnsformers will automatically be passed through\n","x= np.array(ct.fit_transform(x))\n","# x= ct.fit_transform(x)\n","print(x)\n","# if we run this cell again and again , hotencoding will be added on 0th column again"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5xEWOVKgsDj9","executionInfo":{"status":"ok","timestamp":1650741943207,"user_tz":-330,"elapsed":15,"user":{"displayName":"Kunal Kashyap","userId":"03732283627136928542"}},"outputId":"e86af8ca-4b8c-459c-fb1b-8677e18ce884"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[619 'France' 0 ... 1 1 101348.88]\n"," [608 'Spain' 0 ... 0 1 112542.58]\n"," [502 'France' 0 ... 1 0 113931.57]\n"," ...\n"," [709 'France' 0 ... 0 1 42085.58]\n"," [772 'Germany' 1 ... 1 0 92888.52]\n"," [792 'France' 0 ... 1 0 38190.78]]\n","\n","\n","\n","[[1.0 0.0 0.0 ... 1 1 101348.88]\n"," [0.0 0.0 1.0 ... 0 1 112542.58]\n"," [1.0 0.0 0.0 ... 1 0 113931.57]\n"," ...\n"," [1.0 0.0 0.0 ... 0 1 42085.58]\n"," [0.0 1.0 0.0 ... 1 0 92888.52]\n"," [1.0 0.0 0.0 ... 1 0 38190.78]]\n"]}]},{"cell_type":"code","source":["#Train split test\n","from sklearn.model_selection import train_test_split\n","x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=1)   #random, if not specified, then on every new exection, the train and test datasets will give different values"],"metadata":{"id":"ru5n-M6ds7pJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#feature scaling\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","x_train=sc.fit_transform(x_train)\n","x_test=sc.transform(x_test)\n","print(x_train)\n","print(x_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ShgN6dbxwRtb","executionInfo":{"status":"ok","timestamp":1650741943208,"user_tz":-330,"elapsed":13,"user":{"displayName":"Kunal Kashyap","userId":"03732283627136928542"}},"outputId":"764348b3-0139-417a-d272-d03c1131999a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[-0.99850112  1.71490137 -0.57273139 ... -1.55337352  0.97725852\n","   0.42739449]\n"," [ 1.00150113 -0.58312392 -0.57273139 ... -1.55337352 -1.02327069\n","  -1.02548708]\n"," [-0.99850112  1.71490137 -0.57273139 ...  0.64376017  0.97725852\n","  -0.94479772]\n"," ...\n"," [ 1.00150113 -0.58312392 -0.57273139 ...  0.64376017  0.97725852\n","  -0.14096853]\n"," [ 1.00150113 -0.58312392 -0.57273139 ...  0.64376017  0.97725852\n","   0.01781218]\n"," [-0.99850112  1.71490137 -0.57273139 ...  0.64376017 -1.02327069\n","  -1.15822478]]\n","[[ 1.00150113 -0.58312392 -0.57273139 ...  0.64376017  0.97725852\n","  -0.05360571]\n"," [ 1.00150113 -0.58312392 -0.57273139 ...  0.64376017 -1.02327069\n","  -0.58392685]\n"," [ 1.00150113 -0.58312392 -0.57273139 ... -1.55337352  0.97725852\n","  -0.16685331]\n"," ...\n"," [-0.99850112 -0.58312392  1.74601919 ... -1.55337352  0.97725852\n","   1.0669965 ]\n"," [-0.99850112  1.71490137 -0.57273139 ...  0.64376017  0.97725852\n","   1.13101314]\n"," [-0.99850112  1.71490137 -0.57273139 ...  0.64376017  0.97725852\n","  -0.88790165]]\n"]}]},{"cell_type":"markdown","source":["**Building the ANN**"],"metadata":{"id":"ttMBMDHmwgvb"}},{"cell_type":"code","source":["#Initializing the ANN\n","ann = tf.keras.models.Sequential() #seq class is taken from models module of the keras library of tensorflow"],"metadata":{"id":"C4JJqZjLwbrp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Adding the input layer and the first hidden layer\n","ann.add(tf.keras.layers.Dense(units = 6,activation='relu')) \n","#add is used for adding hidden layers\n","#keras = Keras acts as an interface for the TensorFlow library.\n","#Dense = Fully connected neural network"],"metadata":{"id":"RJqKr_3Fx-Ju"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Adding second hidden layer\n","ann.add(tf.keras.layers.Dense(units = 6,activation='relu')) "],"metadata":{"id":"CsNtEiIhze60"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Adding the output layer\n","ann.add(tf.keras.layers.Dense(units = 1,activation='sigmoid')) #sigmoid is used for 0 or 1(Exited Column), else if more than two categories in output use 'SOFTMAX' func"],"metadata":{"id":"tRhfDcSwzlrz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Training the ANN**"],"metadata":{"id":"hmQmAmwa0TQ4"}},{"cell_type":"code","source":["#Compiling the ANN\n","ann.compile(optimizer=\"adam\", loss=\"binary_crossentropy\" , metrics= ['accuracy']) #if output==binary(binary_crossentropy) , else output==categorical_crossentropy\n"],"metadata":{"id":"f3E76VQW0ASW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Training the ANN on the training set\n","ann.fit(x_train,y_train,batch_size=32, epochs=100) #epochs==iterations,batch_size==batch of neurons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-0EJ81ro14uo","executionInfo":{"status":"ok","timestamp":1650741986297,"user_tz":-330,"elapsed":41487,"user":{"displayName":"Kunal Kashyap","userId":"03732283627136928542"}},"outputId":"4c1c96f6-48e8-4189-8e9f-b1e2c26fd2a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","250/250 [==============================] - 1s 1ms/step - loss: 0.5625 - accuracy: 0.7429\n","Epoch 2/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.7974\n","Epoch 3/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.8002\n","Epoch 4/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4318 - accuracy: 0.8044\n","Epoch 5/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4228 - accuracy: 0.8080\n","Epoch 6/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4128 - accuracy: 0.8161\n","Epoch 7/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4020 - accuracy: 0.8211\n","Epoch 8/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3909 - accuracy: 0.8295\n","Epoch 9/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3810 - accuracy: 0.8341\n","Epoch 10/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3734 - accuracy: 0.8374\n","Epoch 11/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3683 - accuracy: 0.8382\n","Epoch 12/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3656 - accuracy: 0.8405\n","Epoch 13/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3633 - accuracy: 0.8409\n","Epoch 14/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3618 - accuracy: 0.8407\n","Epoch 15/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3601 - accuracy: 0.8424\n","Epoch 16/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3586 - accuracy: 0.8432\n","Epoch 17/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3581 - accuracy: 0.8447\n","Epoch 18/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3573 - accuracy: 0.8449\n","Epoch 19/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3558 - accuracy: 0.8465\n","Epoch 20/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3549 - accuracy: 0.8478\n","Epoch 21/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3535 - accuracy: 0.8494\n","Epoch 22/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3524 - accuracy: 0.8485\n","Epoch 23/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3507 - accuracy: 0.8489\n","Epoch 24/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3493 - accuracy: 0.8500\n","Epoch 25/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3477 - accuracy: 0.8508\n","Epoch 26/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3461 - accuracy: 0.8529\n","Epoch 27/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3443 - accuracy: 0.8544\n","Epoch 28/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3429 - accuracy: 0.8580\n","Epoch 29/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3420 - accuracy: 0.8602\n","Epoch 30/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3406 - accuracy: 0.8580\n","Epoch 31/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8587\n","Epoch 32/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3391 - accuracy: 0.8590\n","Epoch 33/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3381 - accuracy: 0.8585\n","Epoch 34/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3379 - accuracy: 0.8600\n","Epoch 35/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8593\n","Epoch 36/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8589\n","Epoch 37/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3370 - accuracy: 0.8585\n","Epoch 38/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3363 - accuracy: 0.8602\n","Epoch 39/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8591\n","Epoch 40/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3359 - accuracy: 0.8601\n","Epoch 41/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8610\n","Epoch 42/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8616\n","Epoch 43/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8611\n","Epoch 44/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8611\n","Epoch 45/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8609\n","Epoch 46/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8614\n","Epoch 47/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8602\n","Epoch 48/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8608\n","Epoch 49/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8621\n","Epoch 50/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8609\n","Epoch 51/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8610\n","Epoch 52/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8608\n","Epoch 53/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8614\n","Epoch 54/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8616\n","Epoch 55/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8606\n","Epoch 56/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8621\n","Epoch 57/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8624\n","Epoch 58/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8602\n","Epoch 59/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8614\n","Epoch 60/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8608\n","Epoch 61/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8616\n","Epoch 62/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.8611\n","Epoch 63/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8618\n","Epoch 64/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8605\n","Epoch 65/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8609\n","Epoch 66/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8639\n","Epoch 67/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8605\n","Epoch 68/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8602\n","Epoch 69/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.8622\n","Epoch 70/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.8614\n","Epoch 71/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8614\n","Epoch 72/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.8615\n","Epoch 73/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8629\n","Epoch 74/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8610\n","Epoch 75/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8619\n","Epoch 76/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8626\n","Epoch 77/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8614\n","Epoch 78/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8601\n","Epoch 79/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8615\n","Epoch 80/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8614\n","Epoch 81/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8616\n","Epoch 82/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8605\n","Epoch 83/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8626\n","Epoch 84/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8618\n","Epoch 85/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8618\n","Epoch 86/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8619\n","Epoch 87/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8619\n","Epoch 88/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8618\n","Epoch 89/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8626\n","Epoch 90/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8624\n","Epoch 91/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8616\n","Epoch 92/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8616\n","Epoch 93/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8606\n","Epoch 94/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8611\n","Epoch 95/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8624\n","Epoch 96/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8618\n","Epoch 97/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8626\n","Epoch 98/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8619\n","Epoch 99/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8621\n","Epoch 100/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8618\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f6bbd810710>"]},"metadata":{},"execution_count":82}]},{"cell_type":"markdown","source":["**Making the predictions and evaluating the model**\n","Use our ANN model to predict if the customer with the following informations will leave the bank: \n","\n","Geography: France  \n","Credit Score: 600   \n","Gender: Male        \n","Age: 40 years old             \n","Tenure: 3 years             \n","Balance: 60000        \n","Number of Products: 2     \n","Does this customer have a credit card? Yes\n","Is this customer an Active Member: Yes\n","Estimated Salary: $ 50000\n","So, should we say goodbye to that customer?\n"],"metadata":{"id":"coWdXZG33IvB"}},{"cell_type":"code","source":["print(ann.predict(sc.transform([[1,0,0, 600, 1, 40,3,60000,2,1,1,50000]])) > 0.5) #0.5 is the threshold value to classify into 0 or 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"erR8SkB82Oz_","executionInfo":{"status":"ok","timestamp":1650742025924,"user_tz":-330,"elapsed":490,"user":{"displayName":"Kunal Kashyap","userId":"03732283627136928542"}},"outputId":"44da626d-1db5-4f85-c038-42a6596318e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[False]]\n"]}]},{"cell_type":"code","source":["# Predicting the Test set results\n","y_pred = ann.predict(x_test)\n","y_pred = (y_pred > 0.5)\n","print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n","\n","# Making the Confusion Matrix\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","cm = confusion_matrix(y_test, y_pred)\n","print(cm)\n","accuracy_score(y_test, y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2eYpVdfJ4n4x","executionInfo":{"status":"ok","timestamp":1650742201801,"user_tz":-330,"elapsed":602,"user":{"displayName":"Kunal Kashyap","userId":"03732283627136928542"}},"outputId":"4b965e47-c054-4621-ec4a-f805be7d08ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0 0]\n"," [0 0]\n"," [0 0]\n"," ...\n"," [0 0]\n"," [0 0]\n"," [0 0]]\n","[[1532   53]\n"," [ 210  205]]\n"]},{"output_type":"execute_result","data":{"text/plain":["0.8685"]},"metadata":{},"execution_count":85}]},{"cell_type":"code","source":[""],"metadata":{"id":"fVsXL2P85wib"},"execution_count":null,"outputs":[]}]}